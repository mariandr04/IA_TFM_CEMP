# Instalar librerÃ­as necesarias
!pip install imbalanced-learn

# Importar librerÃ­as
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns
from google.colab import drive
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import roc_curve, roc_auc_score, auc
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report, confusion_matrix

# ConfiguraciÃ³n visual
sns.set(style="whitegrid")
plt.rcParams["figure.figsize"] = (10, 6)

# Montar Google Drive
drive.mount('/content/drive')

# Leer el archivo CSV
file_path = '/content/drive/My Drive/Colab Notebooks/heart.csv'
df = pd.read_csv(file_path)

# Mostrar primeras filas
print("Primeras filas del dataset:")
display(df.head())

# InformaciÃ³n general
print("\nInformaciÃ³n del dataset:")
print(df.info())

# EstadÃ­sticas descriptivas
print("\nEstadÃ­sticas descriptivas:")
display(df.describe())




# -------------------------------------------
# 1. Binarizar la columna 'num' sin alterar el original
# -------------------------------------------
df_bin = df.copy()
# Histogramas + KDE de variables numÃ©ricas
numeric_cols = df.select_dtypes(include='number').columns.drop('num')
for col in numeric_cols:
    plt.figure()
    sns.histplot(df[col], kde=True)
    plt.title(f'DistribuciÃ³n de {col}')
    plt.show()
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
df_bin['num_binarizada'] = df_bin['num'].apply(lambda x: 1 if x > 0 else 0)

# Eliminar la columna original 'num'
df_bin.drop(columns=['num'], inplace=True)

# Calcular proporciones
tasa = df_bin['num_binarizada'].value_counts(normalize=True).sort_index()

labels = ['Sano (0)', 'Enfermo (1)']

# Dibujar barplot
plt.figure(figsize=(6,4))
ax = sns.barplot(x=tasa.index, y=tasa.values, palette='Blues')
plt.xticks([0,1], labels)
plt.ylabel('ProporciÃ³n')
plt.ylim(0,1)
plt.title('ProporciÃ³n de variable objetivo(num) con porcentaje')

# Anotar porcentaje
for p, pct in zip(ax.patches, tasa.values):
    ax.annotate(f'{pct*100:.1f}%',
                (p.get_x() + p.get_width() / 2, p.get_height()),
                ha='center', va='bottom',
                fontsize=12)

plt.tight_layout()
plt.show()

# -------------------------------------------
# 2. AnÃ¡lisis de variables
# -------------------------------------------
categorical_vars = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']

for var in categorical_vars:
    print(f"\n--- AnÃ¡lisis de la variable '{var}' ---")

    # Mostrar valores Ãºnicos y conteos
    print(f"Valores Ãºnicos: {df_bin[var].unique()}")
    print(df_bin[var].value_counts())

    # GrÃ¡fico de barras agrupado por clase de enfermedad
    plt.figure(figsize=(6, 4))
    sns.countplot(x=var, hue='num_binarizada', data=df_bin, palette='Set2')
    plt.title(f'RelaciÃ³n entre {var} y num_binarizada')
    plt.xlabel(var)
    plt.ylabel('Frecuencia')
    plt.grid(axis='y', linestyle='--', alpha=0.6)
    plt.tight_layout()
    plt.show()

    # Tasa de enfermedad por categorÃ­a
    tasa = df_bin.groupby(var)['num_binarizada'].mean().round(3)
    print(f"Tasa de enfermedad cardÃ­aca (proporciÃ³n de casos positivos) por categorÃ­a en '{var}':\n{tasa}")


# â€”â€”â€”â€”â€”â€” VisualizaciÃ³n especÃ­fica para 'cp' y 'exang' â€”â€”â€”â€”â€”â€”

# 1) Countplot agrupado de 'cp'
plt.figure(figsize=(6,4))
sns.countplot(
    data=df_bin,
    x='cp',
    hue='num_binarizada',
    palette='Set2'
)
plt.title('DistribuciÃ³n de dolor torÃ¡cico (cp) por clase')
plt.xlabel('Tipo de dolor torÃ¡cico (cp)')
plt.ylabel('Frecuencia')
plt.legend(title='Enfermedad', labels=['Sano (0)', 'Enfermo (1)'])
plt.tight_layout()
plt.show()

# 2) Barplot de proporciÃ³n enfermos por categorÃ­a 'cp'
tasa_cp = df_bin.groupby('cp')['num_binarizada'].mean().reset_index()
plt.figure(figsize=(6,4))
sns.barplot(
    data=tasa_cp,
    x='cp',
    y='num_binarizada',
    palette='Blues'
)
plt.title('Tasa de enfermedad cardÃ­aca por tipo de dolor torÃ¡cico')
plt.xlabel('Tipo de dolor torÃ¡cico (cp)')
plt.ylabel('ProporciÃ³n de enfermos')
plt.ylim(0,1)
plt.tight_layout()
plt.show()

# 3) Countplot agrupado de 'exang'
plt.figure(figsize=(6,4))
sns.countplot(
    data=df_bin,
    x='exang',
    hue='num_binarizada',
    palette='Set2'
)
plt.title('Angina inducida por ejercicio (exang) por clase')
plt.xlabel('exang (0 = No, 1 = SÃ­)')
plt.ylabel('Frecuencia')
plt.legend(title='Enfermedad', labels=['Sano (0)', 'Enfermo (1)'])
plt.tight_layout()
plt.show()

# 4) Barplot de proporciÃ³n enfermos por categorÃ­a 'exang'
tasa_exang = df_bin.groupby('exang')['num_binarizada'].mean().reset_index()
plt.figure(figsize=(6,4))
sns.barplot(
    data=tasa_exang,
    x='exang',
    y='num_binarizada',
    palette='Blues'
)
plt.title('Tasa de enfermedad cardÃ­aca segÃºn angina inducida por ejercicio')
plt.xlabel('exang (0 = No, 1 = SÃ­)')
plt.ylabel('ProporciÃ³n de enfermos')
plt.ylim(0,1)
plt.tight_layout()
plt.show()

# Definir el tamaÃ±o de la grilla
n_cols = 4
n_rows = (len(categorical_vars) + n_cols - 1) // n_cols  # nÃºmero de filas necesarias

plt.figure(figsize=(5 * n_cols, 4 * n_rows))  # tamaÃ±o total del lienzo

for i, var in enumerate(categorical_vars, 1):
    plt.subplot(n_rows, n_cols, i)
    sns.countplot(x=var, hue='num_binarizada', data=df_bin, palette='Set2')
    plt.title(f'{var} vs num_binarizada')
    plt.xlabel(var)
    plt.ylabel('Frecuencia')
    plt.grid(axis='y', linestyle='--', alpha=0.5)
    plt.tight_layout()

plt.suptitle('DistribuciÃ³n de variables categÃ³ricas por clase', fontsize=16, y=1.02)
plt.show()


# -------------------------------------------
# 3. Mapa de calor con la matriz de correlaciÃ³n
# -------------------------------------------
corr_matrix = df_bin.corr()

plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', square=True, linewidths=0.5, cbar_kws={"shrink": 0.8})
plt.title("Mapa de calor de correlaciÃ³n entre variables (con num_binarizada)")
plt.tight_layout()
plt.show()


# -------------------------------------------
# 4.GrÃ¡fico de Barras de Coeficientes de CorrelaciÃ³n
# -------------------------------------------

target_column = df_bin.columns[-1]  # Ãšltima columna del CSV como la columna objetivo

# Calcular la correlaciÃ³n de todas las columnas con la columna objetivo
correlations = df_bin.corr()[target_column].drop(target_column)  # Excluir la autocorrelaciÃ³n de la columna objetivo
# Ordenar las correlaciones de mayor a menor
correlations_sorted = correlations.sort_values(ascending=True)

# Crear el grÃ¡fico de barras
plt.figure(figsize=(10, 6))
barplot = sns.barplot(x=correlations_sorted.values,y=correlations_sorted.index,hue=correlations_sorted.values,palette="coolwarm")  # Azul para correlaciÃ³n negativa, rojo para positiva
plt.title(f"CorrelaciÃ³n de atributos con {target_column}")
plt.xlabel("Coeficiente de CorrelaciÃ³n")
plt.ylabel("Atributos")
# AÃ±adir una barra de color al lado derecho del grÃ¡fico para explicar el significado de los colores
# Crear el mapeo de color y asociarlo con la barra de color
#plt.xlim(-0.1, 1)
norm = mpl.colors.Normalize(vmin=-0.1, vmax=1)
sm = plt.cm.ScalarMappable(cmap="coolwarm", norm=norm)
sm.set_array([])  # Necesario para que el ScalarMappable sea compatible con colorbar
cbar = plt.colorbar(sm, orientation="vertical", ax=barplot.axes)
cbar.set_label("Nivel de CorrelaciÃ³n")
plt.tight_layout()  # Ajuste automÃ¡tico del espacio
plt.show()

# -------------------------------------------
# 4.Imputacion y Normalizacion
# -------------------------------------------
# -------------------------------------------
# 4.1 Identificar columnas con valores faltantes o caracteres no numÃ©ricos
# -------------------------------------------
print("\n RevisiÃ³n de columnas con valores faltantes o datos invÃ¡lidos:\n")

# Detectar columnas con valores nulos
missing_values = df_bin.isnull().sum()
missing_columns = missing_values[missing_values > 0]

# Detectar caracteres raros (por ejemplo '?') en variables categÃ³ricas
strange_chars = (df_bin[categorical_vars] == '?').sum()
strange_columns = strange_chars[strange_chars > 0]

# Imprimir resultados
if missing_columns.empty and strange_columns.empty:
    print(" No se encontraron valores faltantes ni caracteres extraÃ±os en el dataset.")
else:
    if not missing_columns.empty:
        print("âš ï¸ Columnas con valores nulos:\n", missing_columns)
    if not strange_columns.empty:
        print("âš ï¸ Columnas con caracteres extraÃ±os ('?'):\n", strange_columns)

# Convertir los '?' a np.nan para imputar si se encuentran
for col in strange_columns.index:
    df_bin[col] = df_bin[col].replace('?', np.nan)

# -------------------------------------------
# 4.2 Imputar columnas si es necesario
# -------------------------------------------
if not missing_columns.empty or not strange_columns.empty:
    print("\nğŸ”§ Realizando imputaciÃ³n de datos...")

    imputador = SimpleImputer(strategy='most_frequent')  # Ãºtil para categÃ³ricas
    df_bin[missing_columns.index.tolist() + strange_columns.index.tolist()] = imputador.fit_transform(
        df_bin[missing_columns.index.tolist() + strange_columns.index.tolist()]
    )
    print(" ImputaciÃ³n completada.")
else:
    print(" No se requiere imputaciÃ³n.")

# -------------------------------------------
# 4.3 Normalizar variables numÃ©ricas continuas
# -------------------------------------------


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
#  Pairplot de variables clave
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

print("Pairplot.......")
vars_sel = ['age', 'trestbps', 'chol', 'thalach', 'num_binarizada']
sns.pairplot(df_bin[vars_sel], hue='num_binarizada', corner=True)
plt.show()


# Boxplots especÃ­ficos
for col in ['oldpeak', 'thalach']:
    plt.figure()
    sns.boxplot(x='num_binarizada', y=col, data=df_bin)
    plt.title(f'Boxplot de {col} por clase')
    plt.show()


print("\nğŸ“ Normalizando variables numÃ©ricas continuas...")


# Conteo de outliers por IQR
outliers = {}
numeric_cols = df_bin.select_dtypes(include='number').columns.drop('num_binarizada')
for col in numeric_cols:
    Q1, Q3 = df_bin[col].quantile([0.25, 0.75])
    IQR = Q3 - Q1
    mask = (df_bin[col] < Q1 - 1.5*IQR) | (df_bin[col] > Q3 + 1.5*IQR)
    outliers[col] = mask.sum()
pd.Series(outliers).sort_values().plot.bar(figsize=(10,4))
plt.title('NÃºmero de outliers por variable')
plt.show()
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”



# Excluir las categÃ³ricas y la columna objetivo
features_to_normalize = df_bin.drop(columns=categorical_vars + ['num_binarizada']).columns.tolist()

scaler = MinMaxScaler()
df_bin[features_to_normalize] = scaler.fit_transform(df_bin[features_to_normalize])

### Bar chart de media Â± desviaciÃ³n estÃ¡ndar
# Agrupar y calcular media y desviaciÃ³n estÃ¡ndar por clase
stats = df_bin.groupby('num_binarizada')[numeric_cols].agg(['mean','std'])

# Extraer medias y desviaciones estÃ¡ndar de la clase 1
means_class_1 = stats.loc[1, (slice(None), 'mean')]
stds_class_1 = stats.loc[1, (slice(None), 'std')]

# Extraer medias de la clase 0 para calcular diferencia
means_class_0 = stats.loc[0, (slice(None), 'mean')]

# Calcular diferencia de medias
mean_diff = means_class_1.values - means_class_0.values

# Crear un nuevo DataFrame para graficar
plot_df = pd.DataFrame({
    'mean': means_class_1.values,
    'std': stds_class_1.values,
    'mean_diff': mean_diff
}, index=means_class_1.index)

# Ordenar por la diferencia de medias
plot_df.sort_values('mean_diff', inplace=True)

# Graficar
plot_df.plot.bar(y='mean', yerr='std', figsize=(12,6), legend=False)
plt.ylabel('Valor medio')
plt.title('Media (clase 1) Â± DesviaciÃ³n estÃ¡ndar')
plt.tight_layout()
plt.show()



print(f" Variables normalizadas: {features_to_normalize}")

# -------------------------------------------
# 4.4 CodificaciÃ³n one-hot para variables categÃ³ricas
# -------------------------------------------
print("\n Aplicando One-Hot Encoding a variables categÃ³ricas...")

# Convertir las variables categÃ³ricas usando one-hot encoding
df_final = pd.get_dummies(df_bin, columns=categorical_vars, drop_first=True)
# Convertir todas las columnas booleanas a 0 y 1
df_final = df_final.astype({col: 'int' for col in df_final.select_dtypes(include='bool').columns})

print(" One-hot encoding completado.")
print(f" Dimensiones del dataset final: {df_final.shape}")
print("\n Columnas finales:")
print(df_final.columns.tolist())

# -------------------------------------------
# 4.5 VisualizaciÃ³n previa del dataset final
# -------------------------------------------
print("\n Vista previa del dataset listo para entrenar:")
display(df_final.head())

### Heatmap: correlaciÃ³n original vs preprocesada

fig, axs = plt.subplots(1,2, figsize=(16,6))
sns.heatmap(df.corr(), ax=axs[0], cmap='coolwarm', cbar=False)
axs[0].set_title('CorrelaciÃ³n original')
sns.heatmap(df_bin.corr(), ax=axs[1], cmap='coolwarm', cbar=False)
axs[1].set_title('CorrelaciÃ³n preprocesada')
plt.show()



# Guardar el dataset preprocesado
output_path = '/content/drive/My Drive/Colab Notebooks/heart_preprocesado.csv'
df_final.to_csv(output_path, index=False)
print(f"\n Dataset final guardado en: {output_path}")

print(f"\n Revisando que la clase objetivo tenga datos balanceados {output_path}")
print(df_final['num_binarizada'].value_counts(normalize=True))
print(df_final['num_binarizada'].value_counts())


# -------------------------------------------
# 5 Fase de entrenamiento
# -------------------------------------------

# Leer el archivo CSV
input_path = '/content/drive/My Drive/Colab Notebooks/heart_preprocesado.csv'
df_train = pd.read_csv(input_path)
df_handle = df_train.copy()


# Separar caracterÃ­sticas (X) y variable objetivo (y)
X = df_handle.drop(columns=['num_binarizada'])
y = df_handle['num_binarizada']

print("âœ… SeparaciÃ³n realizada. X tiene shape:", X.shape)
print("y contiene:", y.value_counts().to_dict())

# strafity se usa sobre todo cuando no hay un balance 50% y 50% de los datos
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print("Entrenamiento:", X_train.shape, y_train.shape)
print("Prueba:", X_test.shape, y_test.shape)

# Definir los hiperparÃ¡metros a buscar
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 5, 10],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2],
    'max_features': ['sqrt', 'log2']
}

# 1. Crear el modelo
modelo_rf = RandomForestClassifier(n_estimators=100, random_state=42)

# 2. Entrenar el modelo
modelo_rf.fit(X_train, y_train)

# 3. Realizar predicciones
y_pred = modelo_rf.predict(X_test)

# 4. Evaluar resultados
print(" Accuracy:", accuracy_score(y_test, y_pred))
print("\n Reporte de clasificaciÃ³n:")
print(classification_report(y_test, y_pred))


# Importancia de variables del RF
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
importances = pd.Series(modelo_rf.feature_importances_, index=X_train.columns)
importances.sort_values().plot.barh(figsize=(8,10))
plt.title('Importancia de variables â€“ Random Forest')
plt.xlabel('Importancia')
plt.show()

# 5. Matriz de confusiÃ³n


cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('PredicciÃ³n')
plt.ylabel('Real')
plt.title(' Matriz de ConfusiÃ³n - Random Forest')
plt.show()

##  ROC, AUC

y_probs_rf = modelo_rf.predict_proba(X_test)[:, 1]  # Probabilidad clase positiva
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_probs_rf)
auc_rf = roc_auc_score(y_test, y_probs_rf)

plt.figure(figsize=(8, 6))
plt.plot(fpr_rf, tpr_rf, color='blue', label=f'Random Forest (AUC = {auc_rf:.3f})', linewidth=2)
plt.plot([0, 1], [0, 1], 'k--')  # LÃ­nea diagonal para referencia
plt.xlabel('Tasa de Falsos Positivos (FPR)')
plt.ylabel('Tasa de Verdaderos Positivos (TPR)')
plt.title('Curva ROC - Random Forest')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

##################################################################
# modelo Gradient Boosting
modelo_gb = GradientBoostingClassifier(random_state=42)

# Entrenar el modelo
modelo_gb.fit(X_train, y_train)

# Realizar predicciones
y_pred_gb = modelo_gb.predict(X_test)

# Evaluar resultados
print(" Resultados con Gradient Boosting:")
print("Accuracy:", accuracy_score(y_test, y_pred_gb))
print("\nReporte de clasificaciÃ³n:")
print(classification_report(y_test, y_pred_gb))

# Matriz de confusiÃ³n para Gradient Boosting
cm_gb = confusion_matrix(y_test, y_pred_gb)
sns.heatmap(cm_gb, annot=True, fmt='d', cmap='Greens')
plt.xlabel('PredicciÃ³n')
plt.ylabel('Real')
plt.title(' Matriz de ConfusiÃ³n - Gradient Boosting')
plt.show()

### ROC, AUC###
y_probs_gb = modelo_gb.predict_proba(X_test)[:, 1]  # Probabilidad clase positiva
fpr_gb, tpr_gb, _ = roc_curve(y_test, y_probs_gb)
auc_gb = roc_auc_score(y_test, y_probs_gb)

plt.figure(figsize=(8, 6))
plt.plot(fpr_gb, tpr_gb, color='green', label=f'Gradient Boosting (AUC = {auc_gb:.3f})', linewidth=2)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('Tasa de Falsos Positivos (FPR)')
plt.ylabel('Tasa de Verdaderos Positivos (TPR)')
plt.title('Curva ROC - Gradient Boosting')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

########Red neuronal simple#########
# Crear una red neuronal simple
# Modelo de red neuronal simple
nn_model = Sequential()
nn_model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))
nn_model.add(Dense(16, activation='relu'))
nn_model.add(Dense(1, activation='sigmoid'))

# Compilar y entrenar
nn_model.compile(optimizer=Adam(learning_rate=0.001),
                 loss='binary_crossentropy',
                 metrics=['accuracy'])
nn_model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)

# Predicciones
y_pred_nn_proba = nn_model.predict(X_test)
y_pred_nn = (y_pred_nn_proba > 0.5).astype(int)

# --- Matriz de confusiÃ³n (grÃ¡fica) ---
cm = confusion_matrix(y_test, y_pred_nn)
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="pink", xticklabels=[0,1], yticklabels=[0,1])
plt.title("Matriz de ConfusiÃ³n - Red Neuronal")
plt.xlabel("PredicciÃ³n")
plt.ylabel("Valor Real")
plt.show()

# --- Reporte de clasificaciÃ³n ---
print("\n--- Red Neuronal ---")
print("Reporte de ClasificaciÃ³n:")
print(classification_report(y_test, y_pred_nn))

# --- Curva ROC y AUC ---
fpr, tpr, thresholds = roc_curve(y_test, y_pred_nn_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6,4))
plt.plot(fpr, tpr, color='hotpink', lw=2, label='ROC curve (AUC = %0.3f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--', lw=1)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos', color='deeppink')
plt.ylabel('Tasa de Verdaderos Positivos', color='deeppink')
plt.title('Curva ROC - Red Neuronal', color='deeppink')
plt.legend(loc="lower right", facecolor='white')
plt.grid(color='lightpink')
plt.show()
